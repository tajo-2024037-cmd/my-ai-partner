import streamlit as st
import google.generativeai as genai
import os

# --- 1. APIã‚­ãƒ¼ã®è¨­å®š ---
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("Streamlitã®Secretsã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# --- 2. UIãƒ‡ã‚¶ã‚¤ãƒ³ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ï¼‰ ---
st.set_page_config(page_title="My AI Partner", layout="centered")

st.markdown("""
    <style>
    .stApp { background-color: #ffffff; }
    .main-title {
        font-family: 'Hiragino Sans', sans-serif;
        color: #666666;
        text-align: center;
        font-size: 0.9rem; /* ã‚¿ã‚¤ãƒˆãƒ«ã‚µã‚¤ã‚ºã‚’ä»¥å‰ã®åŠåˆ†ã«å›ºå®š */
        font-weight: bold;
        padding-bottom: 8px;
        margin-bottom: 20px;
        border-bottom: 1px solid #f0f0f0;
    }
    .stChatMessage { background-color: transparent !important; border: none !important; padding: 5px 0px !important; }
    </style>
    <div class="main-title">My AI Partner</div>
""", unsafe_allow_html=True)

# --- 3. ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š (æœ€æ–°ã® Gemini 2.5 Flash ã‚’æŒ‡å®š) ---
# 2.5ã‚·ãƒªãƒ¼ã‚ºã¯å®‰å®šæ€§ãŒé«˜ãã€ç„¡æ–™æ ã®ã‚¨ãƒ©ãƒ¼(429)ã‚‚å‡ºã«ãã„è¨­è¨ˆã§ã™ã€‚
model = genai.GenerativeModel('gemini-2.5-flash')

# --- 4. ä¼šè©±å±¥æ­´ã®ç®¡ç†ã¨ã‚¯ãƒªã‚¢æ©Ÿèƒ½ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

with st.sidebar:
    st.title("Settings")
    if st.button("ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ"):
        st.session_state.messages = []
        st.rerun()

# å±¥æ­´ã®è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 5. å…¥åŠ›ã¨æœ€æ–°ã®æ€§æ ¼åˆ¤å®š ---
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # å±¥æ­´ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ ï¼ˆç›´è¿‘2ä»¶ï¼‰
    context = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-3:-1]])

    # å…±é€šãƒ«ãƒ¼ãƒ«ï¼ˆçµµæ–‡å­—æŠ‘åˆ¶ï¼‰
    base_rule = "å›ç­”ã¯ã‚¿ãƒ¡å£ã§ã€‚æ•¬èªç¦æ­¢ã€‚çµµæ–‡å­—ã¯1å›ç­”ã«ã¤ã1ã¤ã¾ã§ã€‚çŸ­æ–‡ã§ç­”ãˆã¦ã€‚"

    # æ€§æ ¼åˆ¤å®š
    p = prompt.lower()
    if any(k in p for k in ["ãªãœ", "æ–¹æ³•", "æ•™ãˆ"]):
        char_setting = f"{base_rule} çŸ¥çš„ãªå…ˆç”Ÿã¨ã—ã¦ç°¡æ½”ã«ã€‚ å†’é ­:ğŸ“"
    elif any(k in p for k in ["ç›®æ¨™", "é ‘å¼µã‚‹", "ã‚„ã‚‹æ°—"]):
        char_setting = f"{base_rule} ç†±è¡€ã‚³ãƒ¼ãƒã¨ã—ã¦ä¸€è¨€ã§åŠ±ã¾ã—ã¦ã€‚ å†’é ­:ğŸ”¥"
    elif any(k in p for k in ["ç–²ã‚Œ", "è‡ªç”±", "æ—…"]):
        char_setting = f"{base_rule} è‡ªç”±ãªæ—…äººã¨ã—ã¦ã€‚æ‚Ÿã£ãŸã‚ˆã†ãªçŸ­æ–‡ã§ã€‚ å†’é ­:ğŸŒ"
    elif any(k in p for k in ["æ‚©ã¿", "ç›¸è«‡", "æ‚²ã—ã„"]):
        char_setting = f"{base_rule} å„ªã—ã„å…ˆè¼©ã¨ã—ã¦å¯„ã‚Šæ·»ã£ã¦ã€‚ å†’é ­:ğŸŒ¸"
    else:
        char_setting = f"{base_rule} ä»²ã®è‰¯ã„è¦ªå‹ã¨ã—ã¦ã€‚ å†’é ­:âœ¨"

    with st.chat_message("assistant"):
        try:
            full_prompt = f"{char_setting}\n\nä¼šè©±å±¥æ­´:\n{context}\n\nå…¥åŠ›: {prompt}"
            response = model.generate_content(full_prompt)
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error("ç¾åœ¨ã€AIãŒå°‘ã—ä¼‘æ†©ã—ã¦ã„ã‚‹ã¿ãŸã„ã€‚1åˆ†å¾Œã«ã¾ãŸè©±ã—ã‹ã‘ã¦ã¿ã¦ï¼")
